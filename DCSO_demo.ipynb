{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aom(scores, n_buckets, n_estimators, standard=True):\n",
    "    '''\n",
    "    Average of Maximum - An ensemble method for outlier detection\n",
    "    Aggarwal, C.C. and Sathe, S., 2015. Theoretical foundations and algorithms\n",
    "    for outlier ensembles. ACM SIGKDD Explorations Newsletter, 17(1), pp.24-47.\n",
    "    :param scores:\n",
    "    :param n_buckets:\n",
    "    :param n_estimators:\n",
    "    :param standard:\n",
    "    :return:\n",
    "    '''\n",
    "    scores = np.asarray(scores)\n",
    "    if scores.shape[1] != n_estimators:\n",
    "        raise ValueError('score matrix should be n_samples by n_estimaters')\n",
    "\n",
    "    scores_aom = np.zeros([scores.shape[0], n_buckets])\n",
    "\n",
    "    n_estimators_per_bucket = int(n_estimators / n_buckets)\n",
    "    if n_estimators % n_buckets != 0:\n",
    "        Warning('n_estimators / n_buckets leads to a remainder')\n",
    "\n",
    "    # shuffle the estimator order\n",
    "    estimators_list = list(range(0, n_estimators, 1))\n",
    "    np.random.shuffle(estimators_list)\n",
    "\n",
    "    head = 0\n",
    "    for i in range(0, n_estimators, n_estimators_per_bucket):\n",
    "        tail = i + n_estimators_per_bucket\n",
    "        batch_ind = int(i / n_estimators_per_bucket)\n",
    "\n",
    "        scores_aom[:, batch_ind] = np.max(\n",
    "            scores[:, estimators_list[head:tail]], axis=1)\n",
    "\n",
    "        head = head + n_estimators_per_bucket\n",
    "        tail = tail + n_estimators_per_bucket\n",
    "\n",
    "    return np.mean(scores_aom, axis=1)\n",
    "\n",
    "\n",
    "def moa(scores, n_buckets, n_estimators):\n",
    "    '''\n",
    "    Maximum of Average - An ensemble method for outlier detection\n",
    "    Aggarwal, C.C. and Sathe, S., 2015. Theoretical foundations and algorithms\n",
    "    for outlier ensembles. ACM SIGKDD Explorations Newsletter, 17(1), pp.24-47.\n",
    "    :param scores:\n",
    "    :param n_buckets:\n",
    "    :param n_estimators:\n",
    "    :param standard:\n",
    "    :return:\n",
    "    '''\n",
    "    scores = np.asarray(scores)\n",
    "    if scores.shape[1] != n_estimators:\n",
    "        raise ValueError('score matrix should be n_samples by n_estimaters')\n",
    "\n",
    "    scores_moa = np.zeros([scores.shape[0], n_buckets])\n",
    "\n",
    "    n_estimators_per_bucket = int(n_estimators / n_buckets)\n",
    "    if n_estimators % n_buckets != 0:\n",
    "        Warning('n_estimators / n_buckets leads to a remainder')\n",
    "\n",
    "    # shuffle the estimator order\n",
    "    estimators_list = list(range(0, n_estimators, 1))\n",
    "    np.random.shuffle(estimators_list)\n",
    "\n",
    "    head = 0\n",
    "    for i in range(0, n_estimators, n_estimators_per_bucket):\n",
    "        tail = i + n_estimators_per_bucket\n",
    "        batch_ind = int(i / n_estimators_per_bucket)\n",
    "\n",
    "        scores_moa[:, batch_ind] = np.mean(\n",
    "            scores[:, estimators_list[head:tail]], axis=1)\n",
    "\n",
    "        head = head + n_estimators_per_bucket\n",
    "        tail = tail + n_estimators_per_bucket\n",
    "\n",
    "    return np.max(scores_moa, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2b737749df36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-2b737749df36>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_isfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/neighbors/_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from scipy.stats import scoreatpercentile\n",
    "from scipy.stats import rankdata\n",
    "from scipy.special import erf\n",
    "\n",
    "\n",
    "class Knn(object):\n",
    "    \"\"\"\n",
    "    Knn class for outlier detection\n",
    "    support original knn, average knn, and median knn\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=1, contamination=0.05, method='largest'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.contamination = contamination\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X_train):\n",
    "        self.X_train = X_train\n",
    "        self._isfitted = True\n",
    "        self.tree = KDTree(X_train)\n",
    "\n",
    "        neigh = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        neigh.fit(self.X_train)\n",
    "\n",
    "        result = neigh.kneighbors(n_neighbors=self.n_neighbors,\n",
    "                                  return_distance=True)\n",
    "        dist_arr = result[0]\n",
    "\n",
    "        if self.method == 'largest':\n",
    "            dist = dist_arr[:, -1]\n",
    "        elif self.method == 'mean':\n",
    "            dist = np.mean(dist_arr, axis=1)\n",
    "        elif self.method == 'median':\n",
    "            dist = np.median(dist_arr, axis=1)\n",
    "\n",
    "        self.threshold = scoreatpercentile(dist, 100 * (1 - self.contamination))\n",
    "        self.decision_scores = dist.ravel()\n",
    "        self.y_pred = (self.decision_scores > self.threshold).astype('int')\n",
    "\n",
    "        self.mu = np.mean(self.decision_scores)\n",
    "        self.sigma = np.std(self.decision_scores)\n",
    "\n",
    "    def decision_function(self, X_test):\n",
    "\n",
    "        if not self._isfitted:\n",
    "            NotFittedError('Knn is not fitted yet')\n",
    "\n",
    "        # initialize the output score\n",
    "        pred_score = np.zeros([X_test.shape[0], 1])\n",
    "\n",
    "        for i in range(X_test.shape[0]):\n",
    "            x_i = X_test[i, :]\n",
    "            x_i = np.asarray(x_i).reshape(1, x_i.shape[0])\n",
    "\n",
    "            # get the distance of the current point\n",
    "            dist_arr, ind_arr = self.tree.query(x_i, k=self.n_neighbors)\n",
    "\n",
    "            if self.method == 'largest':\n",
    "                dist = dist_arr[:, -1]\n",
    "            elif self.method == 'mean':\n",
    "                dist = np.mean(dist_arr, axis=1)\n",
    "            elif self.method == 'median':\n",
    "                dist = np.median(dist_arr, axis=1)\n",
    "\n",
    "            pred_score_i = dist[-1]\n",
    "\n",
    "            # record the current item\n",
    "            pred_score[i, :] = pred_score_i\n",
    "\n",
    "        return pred_score\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        pred_score = self.decision_function(X_test)\n",
    "        return (pred_score > self.threshold).astype('int')\n",
    "\n",
    "    def predict_proba(self, X_test, method='linear'):\n",
    "        test_scores = self.decision_function(X_test)\n",
    "        train_scores = self.decision_scores\n",
    "\n",
    "        if method == 'linear':\n",
    "            scaler = MinMaxScaler().fit(train_scores.reshape(-1, 1))\n",
    "            proba = scaler.transform(test_scores.reshape(-1, 1))\n",
    "            return proba.clip(0, 1)\n",
    "        else:\n",
    "            # turn output into probability\n",
    "            pre_erf_score = (test_scores - self.mu) / (self.sigma * np.sqrt(2))\n",
    "            erf_score = erf(pre_erf_score)\n",
    "            proba = erf_score.clip(0)\n",
    "\n",
    "            # TODO: move to testing code\n",
    "            assert (proba.min() >= 0)\n",
    "            assert (proba.max() <= 1)\n",
    "            return proba\n",
    "\n",
    "    def predict_rank(self, X_test):\n",
    "        test_scores = self.decision_function(X_test)\n",
    "        train_scores = self.decision_scores\n",
    "\n",
    "        ranks = np.zeros([X_test.shape[0], 1])\n",
    "\n",
    "        for i in range(test_scores.shape[0]):\n",
    "            train_scores_i = np.append(train_scores.reshape(-1, 1),\n",
    "                                       test_scores[i])\n",
    "\n",
    "            ranks[i] = rankdata(train_scores_i)[-1]\n",
    "\n",
    "        # return normalized ranks\n",
    "        ranks_norm = ranks / ranks.max()\n",
    "        return ranks_norm\n",
    "\n",
    "##############################################################################\n",
    "samples = [[-1, 0], [0., 0.], [1., 1], [2., 5.], [3, 1]]\n",
    "\n",
    "clf = Knn()\n",
    "clf.fit(samples)\n",
    "\n",
    "scores = clf.decision_function(np.asarray([[2, 3], [6, 8]])).ravel()\n",
    "assert (scores[0] == [2])\n",
    "assert (scores[1] == [5])\n",
    "#\n",
    "labels = clf.predict(np.asarray([[2, 3], [6, 8]])).ravel()\n",
    "assert (labels[0] == [0])\n",
    "assert (labels[1] == [1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
